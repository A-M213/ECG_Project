
import torch
import numpy as np
from models.diffusion import Simple1DUNet, GaussianDiffusion1D
import os

def train_diffusion_model(
    path_clean,
    model_save_path,
    epochs=10,
    batch_size=32,
    lr=1e-3,
    timesteps=200,
    device=None
):
    if device is None:
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ðŸ“Ÿ EntraÃ®nement sur : {device}")

    # Chargement des signaux propres
    #X_train = np.load(path_clean).astype(np.float32)
    X_train = np.load(path_clean, mmap_mode="r")[:1000].astype(np.float32)
    print(f"ðŸ“¥ DonnÃ©es chargÃ©es : {X_train.shape}")

    # Initialisation du modÃ¨le
    model = Simple1DUNet().to(device)
    diffusion = GaussianDiffusion1D(model, timesteps=timesteps, device=device)
    optimizer = torch.optim.Adam(model.parameters(), lr=lr)

    # EntraÃ®nement
    print("ðŸš€ DÃ©but de l'entraÃ®nement DDPM...")
    for epoch in range(epochs):
        losses = []
        model.train()
        for i in range(0, len(X_train), batch_size):
            xb = X_train[i:i+batch_size]
            xb = torch.tensor(xb.transpose(0, 2, 1)).to(device)
            t = torch.randint(0, diffusion.timesteps, (xb.size(0),), device=device).long()

            try:
                loss = diffusion.p_losses(xb, t)
            except Exception as e:
                print("ðŸ”¥ Erreur rencontrÃ©e dans diffusion.p_losses")
                print(f"â†’ xb.shape : {xb.shape}")
                print(f"â†’ t.shape  : {t.shape}")
                raise e
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            losses.append(loss.item())
        print(f"ðŸ“š Ã‰poch {epoch+1}/{epochs} â€“ Loss: {np.mean(losses):.6f}")

    # Sauvegarde
    os.makedirs(os.path.dirname(model_save_path), exist_ok=True)
    torch.save(model.state_dict(), model_save_path)
    print(f"âœ… ModÃ¨le sauvegardÃ© dans : {model_save_path}")
